{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datarobot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking an LLM \"into\" DataRobot\n",
    "\n",
    "### prequisites\n",
    "\n",
    "This example relies on Gpt4o, so the requirement is that you have access to Gpt4o.  This example shows \n",
    "\n",
    "* the use of Azure OpenAI endpoint that is serving Gpt4o for the purposes of inference.  \n",
    "* optional tracing with Langsmith. the default behavior is to trace the prompt with langsmith, but you can pass an additional argument called `trace_prompt` as False in order to skip tracing (probably rtecommendation for production)\n",
    "\n",
    "In order to utilize required credentials,[DataRobot credential manager](https://docs.datarobot.com/en/docs/data/connect-data/stored-creds.html#credentials-management) is being used to keep the Api token.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `./requirements.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./requirements.txt\n",
    "langchain == 0.3.13\n",
    "langchain-community == 0.3.12\n",
    "langchain-core == 0.3.26\n",
    "langchain-openai == 0.2.12\n",
    "langchain-text-splitters == 0.3.4\n",
    "langsmith == 0.1.147"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `./model-metadata.yaml`\n",
    "\n",
    "in model meda data we provide particulars of the model\n",
    "* type of model\n",
    "* runtime parameters, \n",
    "* etc.\n",
    "\n",
    "See the [docs](https://github.com/datarobot/datarobot-user-models/blob/master/MODEL-METADATA.md)\n",
    "\n",
    "Below, we define the runtime parameters for azure openai and langsmith. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./model-metadata.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./model-metadata.yaml \n",
    "name: Langsmith Traced OpenAI gpt-4o\n",
    "type: inference\n",
    "targetType: textgeneration\n",
    "runtimeParameterDefinitions:\n",
    "  - fieldName: AZURE_OPENAI_API_KEY\n",
    "    type: credential\n",
    "    credentialType: api_token\n",
    "    description: Azure OpenAI Api Key\n",
    "  - fieldName: AZURE_OPENAI_ENDPOINT\n",
    "    type: string\n",
    "    defaultValue: https://datarobot-genai-enablement.openai.azure.com/\n",
    "  - fieldName: PROMPT_COLUMN_NAME\n",
    "    type: string\n",
    "    defaultValue: promptText\n",
    "  - fieldName: LANGCHAIN_API_KEY\n",
    "    type: credential\n",
    "    description: token for langsmith tracing\n",
    "  - fieldName: LANGCHAIN_ENDPOINT\n",
    "    type: string\n",
    "    defaultValue: https://api.smith.langchain.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create .env file for environment variables for local tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./.env.template\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./.env.template\n",
    "LANGCHAIN_ENDPOINT=\"https://api.smith.langchain.com\"\n",
    "LANGCHAIN_API_KEY=\"<your-api-key>\"\n",
    "AZURE_OPENAI_API_KEY=\"<api-key>\"\n",
    "AZURE_OPENAI_ENDPOINT=\"<endpoint>\"\n",
    "OPENAI_API_VERSION=2023-05-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `./custom.py`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is what datarobot uses to call your LLM.  \n",
    "\n",
    "In the code that follows, prompts are passed to the score function as a dataframe.  if `LANGCHAIN_TRACING_V2` is set to False, you can pass through a project name to override the environment setting and complete loggins.  You'll see an example of this later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./custom.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./custom.py \n",
    "from datarobot_drum import RuntimeParameters\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.callbacks.tracers import LangChainTracer\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_model(*args, **kwargs):\n",
    "    if (env_key := os.getenv(\"AZURE_OPENAI_API_KEY\")):\n",
    "        api_key = env_key\n",
    "    else:\n",
    "        api_key = RuntimeParameters.get(\"AZURE_OPENAI_API_KEY\")[\"apiToken\"]\n",
    "    if (env_key:= os.getenv(\"AZURE_OPENAI_ENDPOINT\")):\n",
    "        azure_endpoint = env_key\n",
    "    else:\n",
    "        azure_endpoint = RuntimeParameters.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    if (env_key := os.getenv(\"LANGCHAIN_API_KEY\")):\n",
    "        # if this passes, it is expected your endpoint is set up accordingly\n",
    "        pass\n",
    "    else:\n",
    "        # pull langchain credentials from runtime parameters\n",
    "        os.environ[\"LANGCHAIN_API_KEY\"] = RuntimeParameters.get(\"LANGCHAIN_API_KEY\")[\"apiToken\"]\n",
    "        os.environ[\"LANGCHAIN_ENDPOINT\"] = RuntimeParameters.get(\"LANGCHAIN_ENDPOINT\")\n",
    "\n",
    "# open\n",
    "    model = AzureChatOpenAI(\n",
    "        model=\"gpt-4o\",  # i.e., gpt-4o\n",
    "        api_key=api_key,\n",
    "        azure_endpoint=azure_endpoint,\n",
    "        temperature=0.4,\n",
    "        api_version=\"2023-05-15\",\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def score(data, model, **kwargs):\n",
    "    ## langchain tracing is done by passing in additional arguments\n",
    "    responses = []\n",
    "    for idx, prompt in data.iterrows():\n",
    "        if prompt.get(\"trace_prompt\", True):\n",
    "            if langchain_project := prompt.get(\"LANGCHAIN_PROJECT\", \"default\"):\n",
    "                tracer = LangChainTracer(project_name=langchain_project)\n",
    "                response = model.invoke(prompt.promptText, config={\"callbacks\": [tracer]})\n",
    "        else:\n",
    "            # if LANGCHAIN_TRACING_V2 then logging happens to default project\n",
    "            response = model.invoke(prompt.promptText)\n",
    "        responses.append(response.content)\n",
    "    return pd.DataFrame(dict(resultText=responses))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "below, the second prompt is logged to langchain project `math help v3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from custom import *\n",
    "data = pd.DataFrame([\n",
    "    dict(promptText = \"tell me a joke\", trace_prompt = False),\n",
    "    dict(promptText = \"what's up doc?  can we rock\"),\n",
    "    dict(promptText = \"describe bolzano weierstrauss theorem\", LANGCHAIN_PROJECT=\"math help v4\"),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sure, here's a joke for you:\\n\\nWhy don't skel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It sounds like you're referencing the classic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Bolzano-Weierstrass theorem is a fundament...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          resultText\n",
       "0  Sure, here's a joke for you:\\n\\nWhy don't skel...\n",
       "1  It sounds like you're referencing the classic ...\n",
       "2  The Bolzano-Weierstrass theorem is a fundament..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model(code_dir = \".\")\n",
    "response = score(data, model) \n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take this into datarobot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick the appropriate datarobot custom model environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExecutionEnvironment('[DataRobot] Python 3.11 GenAI')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datarobot as dr\n",
    "environment = [env for env in dr.ExecutionEnvironment.list() if env.name == \"[DataRobot] Python 3.11 GenAI\"].pop()\n",
    "environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the list of required runtime parameters (see `model-metadata.yaml` for details)\n",
    "What follows is a list of credentials already being managed by DataRobot.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Credential('662811a051f136d67f7997bd', 'DR_OPENAI_API_KEY', 'api_token'),\n",
       " Credential('676332535bccdbe998577038', 'Langchain API Key', 'api_token')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credentials = [c for c in dr.Credential.list() if c.name in  [\"DR_OPENAI_API_KEY\", \"Langchain API Key\"]]\n",
    "credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll grab the credential ids from the credential list above and set up the run time parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_parameter_values = [\n",
    "    dr.models.runtime_parameters.RuntimeParameterValue(field_name = \"AZURE_OPENAI_API_KEY\", type = \"credential\", value = \"662811a051f136d67f7997bd\"),\n",
    "    dr.models.runtime_parameters.RuntimeParameterValue(field_name = \"LANGCHAIN_API_KEY\", type = \"credential\", value = \"676332535bccdbe998577038\"),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the custom model in the custom model workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cim = dr.CustomInferenceModel.create(name = \"Langchain Traced Gpt4o\", \n",
    "                                    target_type = dr.enums.TARGET_TYPE.TEXT_GENERATION, \n",
    "                                    target_name = \"resultText\", \n",
    "                                    network_egress_policy=dr.enums.NETWORK_EGRESS_POLICY.PUBLIC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add a version with all necessary assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cimv = dr.CustomModelVersion.create_clean(custom_model_id = cim.id, \n",
    "                                          base_environment_id = environment.id, \n",
    "                                          runtime_parameter_values = runtime_parameter_values,                                        \n",
    "                                          files = [(\"custom.py\", \"custom.py\"),\n",
    "                                                   (\"model-metadata.yaml\", \"model-metadata.yaml\"),\n",
    "                                                   (\"requirements.txt\", \"requirements.txt\")])\n",
    "## or \n",
    "# cim = dr.CustomInferenceModel.get(\"67350386bab555bb07182a07\")\n",
    "# cimv = dr.CustomModelVersion.create_from_previous(custom_model_id = cim.id, \n",
    "#                                                    base_environment_id = environment.id,\n",
    "#                                                   files = [(\"custom.py\", \"custom.py\"),\n",
    "#                                                    (\"model-metadata.yaml\", \"model-metadata.yaml\"),\n",
    "#                                                    (\"requirements.txt\", \"requirements.txt\")])\n",
    "                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build the custom model environment (since there was a `requirements.txt` present).  This could take some time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "build = dr.CustomModelVersionDependencyBuild.start_build(cim.id, cimv.id, max_wait = 1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register your test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_dataset_test = dr.Dataset.create_from_in_memory_data(data_frame = data)\n",
    "## or \n",
    "# llm_dataset_test = dr.Dataset.get(\"<dataset-id>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the LLM proxy in DataRobot.  This could take some time.  \n",
    "\n",
    "You should be able to pull up langsmith and check tracing depending on how you set the runtime parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model_test = dr.CustomModelTest.create(cim.id, cimv.id, dataset_id = llm_dataset_test.id, network_egress_policy = dr.enums.NETWORK_EGRESS_POLICY.PUBLIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'succeeded'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model_test.overall_status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a deployment that will be used in the playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prediction_server_id = dr.PredictionEnvironment.list()[-4].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = dr.Deployment.create_from_custom_model_version(custom_model_version_id = cimv.id, \n",
    "                                                            label = \"Traced GPT4o\", \n",
    "                                                            description = \"GPT4o traced via langsmith.  Additional arguments in the payload are required to enable tracing\", \n",
    "                                                            default_prediction_server_id= default_prediction_server_id\n",
    "                                                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check that it is working as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': [{'deploymentApprovalStatus': 'APPROVED',\n",
      "           'prediction': \"Sure, here's a joke for you:\\n\"\n",
      "                         '\\n'\n",
      "                         'Why don’t skeletons fight each other?\\n'\n",
      "                         '\\n'\n",
      "                         'They don’t have the guts!',\n",
      "           'predictionValues': [{'label': 'resultText',\n",
      "                                 'value': \"Sure, here's a joke for you:\\n\"\n",
      "                                          '\\n'\n",
      "                                          'Why don’t skeletons fight each '\n",
      "                                          'other?\\n'\n",
      "                                          '\\n'\n",
      "                                          'They don’t have the guts!'}],\n",
      "           'rowId': 0},\n",
      "          {'deploymentApprovalStatus': 'APPROVED',\n",
      "           'prediction': \"Sure, we can rock! What's on your mind?\",\n",
      "           'predictionValues': [{'label': 'resultText',\n",
      "                                 'value': \"Sure, we can rock! What's on your \"\n",
      "                                          'mind?'}],\n",
      "           'rowId': 1},\n",
      "          {'deploymentApprovalStatus': 'APPROVED',\n",
      "           'prediction': 'The Bolzano-Weierstrass theorem is a fundamental '\n",
      "                         'result in real analysis and topology. It states that '\n",
      "                         'every bounded sequence in \\\\(\\\\mathbb{R}^n\\\\) (the '\n",
      "                         'n-dimensional real number space) has a convergent '\n",
      "                         'subsequence. This theorem is named after '\n",
      "                         'mathematicians Bernard Bolzano and Karl '\n",
      "                         'Weierstrass.\\n'\n",
      "                         '\\n'\n",
      "                         'To break it down:\\n'\n",
      "                         '\\n'\n",
      "                         '1. **Bounded Sequence**: A sequence \\\\((x_n)\\\\) in '\n",
      "                         '\\\\(\\\\mathbb{R}^n\\\\) is bounded if there exists a '\n",
      "                         'real number \\\\(M > 0\\\\) such that the Euclidean norm '\n",
      "                         '\\\\(\\\\|x_n\\\\|\\\\) is less than or equal to \\\\(M\\\\) for '\n",
      "                         'all \\\\(n\\\\). In simpler terms, all the terms of the '\n",
      "                         'sequence lie within a fixed distance from the '\n",
      "                         'origin.\\n'\n",
      "                         '\\n'\n",
      "                         '2. **Convergent Subsequence**: A subsequence '\n",
      "                         '\\\\((x_{n_k})\\\\) of \\\\((x_n)\\\\) is convergent if '\n",
      "                         'there exists a point \\\\(L \\\\in \\\\mathbb{R}^n\\\\) such '\n",
      "                         'that \\\\(\\\\lim_{k \\\\to \\\\infty} x_{n_k} = L\\\\). This '\n",
      "                         'means that the terms of the subsequence get '\n",
      "                         'arbitrarily close to \\\\(L\\\\) as \\\\(k\\\\) becomes very '\n",
      "                         'large.\\n'\n",
      "                         '\\n'\n",
      "                         'The Bolzano-Weierstrass theorem is particularly '\n",
      "                         'important because it guarantees the existence of a '\n",
      "                         'convergent subsequence within any bounded sequence, '\n",
      "                         'which is a key property in the study of compactness '\n",
      "                         'in metric spaces. It is often used to prove other '\n",
      "                         'important results in analysis, such as the '\n",
      "                         'Heine-Borel theorem and the Arzelà-Ascoli theorem.\\n'\n",
      "                         '\\n'\n",
      "                         'In \\\\(\\\\mathbb{R}\\\\) (the real number line), the '\n",
      "                         'theorem simplifies to stating that every bounded '\n",
      "                         'sequence of real numbers has a convergent '\n",
      "                         'subsequence. This is a crucial property that '\n",
      "                         'underpins many other concepts and theorems in real '\n",
      "                         'analysis.',\n",
      "           'predictionValues': [{'label': 'resultText',\n",
      "                                 'value': 'The Bolzano-Weierstrass theorem is '\n",
      "                                          'a fundamental result in real '\n",
      "                                          'analysis and topology. It states '\n",
      "                                          'that every bounded sequence in '\n",
      "                                          '\\\\(\\\\mathbb{R}^n\\\\) (the '\n",
      "                                          'n-dimensional real number space) '\n",
      "                                          'has a convergent subsequence. This '\n",
      "                                          'theorem is named after '\n",
      "                                          'mathematicians Bernard Bolzano and '\n",
      "                                          'Karl Weierstrass.\\n'\n",
      "                                          '\\n'\n",
      "                                          'To break it down:\\n'\n",
      "                                          '\\n'\n",
      "                                          '1. **Bounded Sequence**: A sequence '\n",
      "                                          '\\\\((x_n)\\\\) in \\\\(\\\\mathbb{R}^n\\\\) '\n",
      "                                          'is bounded if there exists a real '\n",
      "                                          'number \\\\(M > 0\\\\) such that the '\n",
      "                                          'Euclidean norm \\\\(\\\\|x_n\\\\|\\\\) is '\n",
      "                                          'less than or equal to \\\\(M\\\\) for '\n",
      "                                          'all \\\\(n\\\\). In simpler terms, all '\n",
      "                                          'the terms of the sequence lie '\n",
      "                                          'within a fixed distance from the '\n",
      "                                          'origin.\\n'\n",
      "                                          '\\n'\n",
      "                                          '2. **Convergent Subsequence**: A '\n",
      "                                          'subsequence \\\\((x_{n_k})\\\\) of '\n",
      "                                          '\\\\((x_n)\\\\) is convergent if there '\n",
      "                                          'exists a point \\\\(L \\\\in '\n",
      "                                          '\\\\mathbb{R}^n\\\\) such that '\n",
      "                                          '\\\\(\\\\lim_{k \\\\to \\\\infty} x_{n_k} = '\n",
      "                                          'L\\\\). This means that the terms of '\n",
      "                                          'the subsequence get arbitrarily '\n",
      "                                          'close to \\\\(L\\\\) as \\\\(k\\\\) becomes '\n",
      "                                          'very large.\\n'\n",
      "                                          '\\n'\n",
      "                                          'The Bolzano-Weierstrass theorem is '\n",
      "                                          'particularly important because it '\n",
      "                                          'guarantees the existence of a '\n",
      "                                          'convergent subsequence within any '\n",
      "                                          'bounded sequence, which is a key '\n",
      "                                          'property in the study of '\n",
      "                                          'compactness in metric spaces. It is '\n",
      "                                          'often used to prove other important '\n",
      "                                          'results in analysis, such as the '\n",
      "                                          'Heine-Borel theorem and the '\n",
      "                                          'Arzelà-Ascoli theorem.\\n'\n",
      "                                          '\\n'\n",
      "                                          'In \\\\(\\\\mathbb{R}\\\\) (the real '\n",
      "                                          'number line), the theorem '\n",
      "                                          'simplifies to stating that every '\n",
      "                                          'bounded sequence of real numbers '\n",
      "                                          'has a convergent subsequence. This '\n",
      "                                          'is a crucial property that '\n",
      "                                          'underpins many other concepts and '\n",
      "                                          'theorems in real analysis.'}],\n",
      "           'rowId': 2}]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "import datarobot as dr \n",
    "import pprint\n",
    "# deployment = dr.Deployment.get(\"673505fb8a477d1f2fbaed3b\")\n",
    "URL = f'{deployment.prediction_environment[\"name\"]}/predApi/v1.0/deployments/{deployment.id}/predictions'\n",
    "headers = {\n",
    "    'Content-Type': 'text/plain; charset=UTF-8',\n",
    "    'Authorization': 'Bearer {}'.format(os.environ[\"DATAROBOT_API_TOKEN\"]),\n",
    "    'DataRobot-Key': deployment.default_prediction_server[\"datarobot-key\"],\n",
    "}\n",
    "query = \"what's up doc?\"\n",
    "response = requests.post( URL, headers = headers, data = data.to_csv(index = False))\n",
    "pprint.pprint(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>promptText</th>\n",
       "      <th>trace_prompt</th>\n",
       "      <th>LANGCHAIN_PROJECT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tell me a joke</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what's up doc, can we rock?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>describe bolzano weierstrauss theorem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>math help v4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              promptText trace_prompt LANGCHAIN_PROJECT\n",
       "0                         tell me a joke        False               NaN\n",
       "1            what's up doc, can we rock?          NaN               NaN\n",
       "2  describe bolzano weierstrauss theorem          NaN      math help v4"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': [{'deploymentApprovalStatus': 'APPROVED',\n",
      "           'prediction': \"Sure, here's a joke for you:\\n\"\n",
      "                         '\\n'\n",
      "                         \"Why don't skeletons fight each other?\\n\"\n",
      "                         '\\n'\n",
      "                         \"They don't have the guts!\",\n",
      "           'predictionValues': [{'label': 'resultText',\n",
      "                                 'value': \"Sure, here's a joke for you:\\n\"\n",
      "                                          '\\n'\n",
      "                                          \"Why don't skeletons fight each \"\n",
      "                                          'other?\\n'\n",
      "                                          '\\n'\n",
      "                                          \"They don't have the guts!\"}],\n",
      "           'rowId': 0}]}\n"
     ]
    }
   ],
   "source": [
    "URL = f'{deployment.prediction_environment[\"name\"]}/predApi/v1.0/deployments/{deployment.id}/predictions'\n",
    "headers = {\n",
    "    'Content-Type': 'application/json; charset=UTF-8',\n",
    "    'Authorization': 'Bearer {}'.format(os.environ[\"DATAROBOT_API_TOKEN\"]),\n",
    "    'DataRobot-Key': deployment.default_prediction_server[\"datarobot-key\"],\n",
    "}\n",
    "query = \"what's up doc?\"\n",
    "response = requests.post( URL, headers = headers, \n",
    "                         data = json.dumps( [\n",
    "                             {\"promptText\": \"tell me a joke\", \"trace_prompt\": True, \"LANGCHAIN_PROJECT\": \"comedian\"}\n",
    "                             ]))\n",
    "pprint.pprint(response.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasty, \n",
    "\n",
    "This last piece will make our LLM available in playground.  Given the way we instrumented tracing in out custom.py file, all prompting done in playground with this llm will be traced and available in the default project for langsmith. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model_llm_validation = dr.genai.CustomModelLLMValidation.create(\n",
    "        prompt_column_name=\"promptText\",\n",
    "        target_column_name=\"resultText\",\n",
    "        deployment_id=deployment.id,\n",
    "        wait_for_completion=True, \n",
    "        name = deployment.__str__()\n",
    "    )\n",
    "\n",
    "assert custom_model_llm_validation.validation_status == \"PASSED\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
